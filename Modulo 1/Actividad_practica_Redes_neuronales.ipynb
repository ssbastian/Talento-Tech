{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install image==1.5.20\n",
        "!pip install numpy==1.114.3\n",
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CNy2Jb2D-Hk",
        "outputId": "ae13664f-9870-4d32-f06d-341d61a5934b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: image==1.5.20 in /usr/local/lib/python3.10/dist-packages (1.5.20)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.10/dist-packages (from image==1.5.20) (5.0.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from image==1.5.20) (9.4.0)\n",
            "Requirement already satisfied: asgiref<4,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from django->image==1.5.20) (3.8.1)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from django->image==1.5.20) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from asgiref<4,>=3.7.0->django->image==1.5.20) (4.12.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.114.3 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0rc1, 1.23.0rc2, 1.23.0rc3, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0rc1, 1.24.0rc2, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0rc1, 1.25.0, 1.25.1, 1.25.2, 1.26.0b1, 1.26.0rc1, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0b1, 2.0.0rc1, 2.0.0rc2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.114.3\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "X, Y = make_circles(n_samples=500, factor=0.5, noise=0.05)\n",
        "\n",
        "#resolucion del mapa de prediccion\n",
        "res = 100\n",
        "\n",
        "#coordenadas del mapa\n",
        "\n",
        "_x0 = np.linspace(-1.5, 1.5, res)\n",
        "_x1 = np.linspace(-1.5, 1.5, res)\n",
        "\n",
        "_pX = np.array(np.meshgrid(_x0, _x1)).T.reshape(-1,2)\n",
        "\n",
        "_pY = np.zeros((res, res))+0.5\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pcolormesh(_x0, _x1, _pY, cmap=\"coolwarm\", vmin=0, vmax=1)\n",
        "\n",
        "plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
        "plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
        "plt.tick_params(labelbottom = False, labelleft=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "lbPmKIyTP1Sx",
        "outputId": "49362a18-bb7d-432e-82cd-a3c9cfe4318f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tensorflow"
      ],
      "metadata": {
        "id": "vz15U-G-XKs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timport tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "from matplotlib import animation\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "#Definition\n",
        "iX = tf.placeholder('float', shape=[None, X.shape[1]])\n",
        "iY = tf.placeholder('float', shape=[None])\n",
        "\n",
        "lr = 0.01 # learning rate\n",
        "nn = [2, 16, 8, 1] # número de neuronas por capa.\n",
        "\n",
        "# Capa 1\n",
        "W1 = tf.Variable(tf.random_normal([nn[0], nn[1]]), name='Weights_1')\n",
        "b1 = tf.Variable(tf.random_normal([nn[1]]), name='bias_1')\n",
        "l1 = tf.nn.relu(tf.add(tf.matmul(iX, W1), b1))\n",
        "\n",
        "# Capa 2\n",
        "W2 = tf.Variable(tf.random_normal([nn[1], nn[2]]), name='Weights_2')\n",
        "b2 = tf.Variable(tf.random_normal([nn[2]]), name='bias_2')\n",
        "l2 = tf.nn.relu(tf.add(tf.matmul(l1, W2), b2))\n",
        "\n",
        "# Capa 3\n",
        "# W3 = tf.Variable(tf.random_normal([nn[0], nn[1]]), name='Weights_1')\n",
        "W3 = tf.Variable(tf.random_normal([nn[2], nn[3]]), name='Weights_3')\n",
        "b3 = tf.Variable(tf.random_normal([nn[3]]), name='bias_3')\n",
        "\n",
        "pY = tf.nn.sigmoid(tf.add(tf.matmul(l2, W3), b3))[:, 0]\n",
        "\n",
        "loss = tf.losses.mean_squared_error(pY, iY)\n",
        "\n",
        "learning_rate = 0.05\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "n_steps = 10000\n",
        "iPY = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  #iteramos n pases de entrenamiento.\n",
        "  for step in range(n_steps):\n",
        "    _, _loss, _pY = sess.run([optimizer, loss, pY], feed_dict={ iX : X, iY : Y})\n",
        "\n",
        "\n",
        "    if step % 25 == 0:\n",
        "      acc = np.mean(np.round(_pY) == Y)\n",
        "      # Impresión de metricas\n",
        "      print('Step', step, '/', n_steps, ' - Loss = ', _loss, ' - ACC =', acc)\n",
        "      _pY = sess.run(pY, feed_dict={iX: _pX}).reshape(res, res)\n",
        "      iPY.append(_pY)\n",
        "\n",
        "ims = []\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "print(\"---Generando animación ----\")\n",
        "\n",
        "for fr in range(len(iPY)):\n",
        "  im = plt.pcolormesh(_x0, _x1, iPY[fr], cmap=\"coolwarm\", animated=True)\n",
        "  plt.scatter(X[Y == 0,0], X[Y == 0,1], c=\"skyblue\")\n",
        "  plt.scatter(X[Y == 1,0], X[Y == 1,1], c=\"salmon\")\n",
        "\n",
        "  plt.tick_params(labelbottom = False, labelleft=False)\n",
        "  ims.append([im])\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "plt.close()\n",
        "''' HTML(ani.to_html_5_video()) '''"
      ],
      "metadata": {
        "id": "pzAHgC0bXJyf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c48a341b-b60d-4075-99b5-b6c3ceae8663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0 / 10000  - Loss =  0.46771118  - ACC = 0.436\n",
            "Step 25 / 10000  - Loss =  0.40563124  - ACC = 0.47\n",
            "Step 50 / 10000  - Loss =  0.32551917  - ACC = 0.488\n",
            "Step 75 / 10000  - Loss =  0.27534825  - ACC = 0.558\n",
            "Step 100 / 10000  - Loss =  0.24617825  - ACC = 0.616\n",
            "Step 125 / 10000  - Loss =  0.21902478  - ACC = 0.694\n",
            "Step 150 / 10000  - Loss =  0.18908565  - ACC = 0.774\n",
            "Step 175 / 10000  - Loss =  0.16221048  - ACC = 0.846\n",
            "Step 200 / 10000  - Loss =  0.14262757  - ACC = 0.902\n",
            "Step 225 / 10000  - Loss =  0.13113727  - ACC = 0.92\n",
            "Step 250 / 10000  - Loss =  0.12268246  - ACC = 0.926\n",
            "Step 275 / 10000  - Loss =  0.116162665  - ACC = 0.928\n",
            "Step 300 / 10000  - Loss =  0.11088569  - ACC = 0.93\n",
            "Step 325 / 10000  - Loss =  0.10624346  - ACC = 0.932\n",
            "Step 350 / 10000  - Loss =  0.10204703  - ACC = 0.934\n",
            "Step 375 / 10000  - Loss =  0.09819145  - ACC = 0.936\n",
            "Step 400 / 10000  - Loss =  0.09458365  - ACC = 0.936\n",
            "Step 425 / 10000  - Loss =  0.091162995  - ACC = 0.936\n",
            "Step 450 / 10000  - Loss =  0.08779072  - ACC = 0.942\n",
            "Step 475 / 10000  - Loss =  0.08408689  - ACC = 0.946\n",
            "Step 500 / 10000  - Loss =  0.078521065  - ACC = 0.954\n",
            "Step 525 / 10000  - Loss =  0.07320227  - ACC = 0.962\n",
            "Step 550 / 10000  - Loss =  0.06845501  - ACC = 0.964\n",
            "Step 575 / 10000  - Loss =  0.06412625  - ACC = 0.97\n",
            "Step 600 / 10000  - Loss =  0.06011733  - ACC = 0.982\n",
            "Step 625 / 10000  - Loss =  0.056468025  - ACC = 0.998\n",
            "Step 650 / 10000  - Loss =  0.053102706  - ACC = 1.0\n",
            "Step 675 / 10000  - Loss =  0.04993637  - ACC = 1.0\n",
            "Step 700 / 10000  - Loss =  0.046983212  - ACC = 1.0\n",
            "Step 725 / 10000  - Loss =  0.04420277  - ACC = 1.0\n",
            "Step 750 / 10000  - Loss =  0.041557934  - ACC = 1.0\n",
            "Step 775 / 10000  - Loss =  0.039081566  - ACC = 1.0\n",
            "Step 800 / 10000  - Loss =  0.036732573  - ACC = 1.0\n",
            "Step 825 / 10000  - Loss =  0.034540523  - ACC = 1.0\n",
            "Step 850 / 10000  - Loss =  0.03254452  - ACC = 1.0\n",
            "Step 875 / 10000  - Loss =  0.030688608  - ACC = 1.0\n",
            "Step 900 / 10000  - Loss =  0.028960913  - ACC = 1.0\n",
            "Step 925 / 10000  - Loss =  0.027352542  - ACC = 1.0\n",
            "Step 950 / 10000  - Loss =  0.025871089  - ACC = 1.0\n",
            "Step 975 / 10000  - Loss =  0.024510356  - ACC = 1.0\n",
            "Step 1000 / 10000  - Loss =  0.02328011  - ACC = 1.0\n",
            "Step 1025 / 10000  - Loss =  0.022150503  - ACC = 1.0\n",
            "Step 1050 / 10000  - Loss =  0.021106668  - ACC = 1.0\n",
            "Step 1075 / 10000  - Loss =  0.020141004  - ACC = 1.0\n",
            "Step 1100 / 10000  - Loss =  0.019218938  - ACC = 1.0\n",
            "Step 1125 / 10000  - Loss =  0.018354056  - ACC = 1.0\n",
            "Step 1150 / 10000  - Loss =  0.017542461  - ACC = 1.0\n",
            "Step 1175 / 10000  - Loss =  0.016780237  - ACC = 1.0\n",
            "Step 1200 / 10000  - Loss =  0.0160672  - ACC = 1.0\n",
            "Step 1225 / 10000  - Loss =  0.015393425  - ACC = 1.0\n",
            "Step 1250 / 10000  - Loss =  0.01475802  - ACC = 1.0\n",
            "Step 1275 / 10000  - Loss =  0.014168561  - ACC = 1.0\n",
            "Step 1300 / 10000  - Loss =  0.013583837  - ACC = 1.0\n",
            "Step 1325 / 10000  - Loss =  0.013005419  - ACC = 1.0\n",
            "Step 1350 / 10000  - Loss =  0.012446378  - ACC = 1.0\n",
            "Step 1375 / 10000  - Loss =  0.011894478  - ACC = 1.0\n",
            "Step 1400 / 10000  - Loss =  0.011338236  - ACC = 1.0\n",
            "Step 1425 / 10000  - Loss =  0.010812602  - ACC = 1.0\n",
            "Step 1450 / 10000  - Loss =  0.010308258  - ACC = 1.0\n",
            "Step 1475 / 10000  - Loss =  0.009798819  - ACC = 1.0\n",
            "Step 1500 / 10000  - Loss =  0.009278996  - ACC = 1.0\n",
            "Step 1525 / 10000  - Loss =  0.008775655  - ACC = 1.0\n",
            "Step 1550 / 10000  - Loss =  0.008290215  - ACC = 1.0\n",
            "Step 1575 / 10000  - Loss =  0.0078606  - ACC = 1.0\n",
            "Step 1600 / 10000  - Loss =  0.007477331  - ACC = 1.0\n",
            "Step 1625 / 10000  - Loss =  0.0071335346  - ACC = 1.0\n",
            "Step 1650 / 10000  - Loss =  0.0068197735  - ACC = 1.0\n",
            "Step 1675 / 10000  - Loss =  0.0065327175  - ACC = 1.0\n",
            "Step 1700 / 10000  - Loss =  0.0062691877  - ACC = 1.0\n",
            "Step 1725 / 10000  - Loss =  0.0060261814  - ACC = 1.0\n",
            "Step 1750 / 10000  - Loss =  0.005800558  - ACC = 1.0\n",
            "Step 1775 / 10000  - Loss =  0.005591834  - ACC = 1.0\n",
            "Step 1800 / 10000  - Loss =  0.0053994055  - ACC = 1.0\n",
            "Step 1825 / 10000  - Loss =  0.005219174  - ACC = 1.0\n",
            "Step 1850 / 10000  - Loss =  0.00505038  - ACC = 1.0\n",
            "Step 1875 / 10000  - Loss =  0.0048922133  - ACC = 1.0\n",
            "Step 1900 / 10000  - Loss =  0.004744053  - ACC = 1.0\n",
            "Step 1925 / 10000  - Loss =  0.0046051675  - ACC = 1.0\n",
            "Step 1950 / 10000  - Loss =  0.004473024  - ACC = 1.0\n",
            "Step 1975 / 10000  - Loss =  0.0043479977  - ACC = 1.0\n",
            "Step 2000 / 10000  - Loss =  0.0042297333  - ACC = 1.0\n",
            "Step 2025 / 10000  - Loss =  0.00411761  - ACC = 1.0\n",
            "Step 2050 / 10000  - Loss =  0.004011169  - ACC = 1.0\n",
            "Step 2075 / 10000  - Loss =  0.003909921  - ACC = 1.0\n",
            "Step 2100 / 10000  - Loss =  0.0038135143  - ACC = 1.0\n",
            "Step 2125 / 10000  - Loss =  0.0037216088  - ACC = 1.0\n",
            "Step 2150 / 10000  - Loss =  0.0036340011  - ACC = 1.0\n",
            "Step 2175 / 10000  - Loss =  0.0035512866  - ACC = 1.0\n",
            "Step 2200 / 10000  - Loss =  0.0034729966  - ACC = 1.0\n",
            "Step 2225 / 10000  - Loss =  0.0033981313  - ACC = 1.0\n",
            "Step 2250 / 10000  - Loss =  0.0033266977  - ACC = 1.0\n",
            "Step 2275 / 10000  - Loss =  0.0032585831  - ACC = 1.0\n",
            "Step 2300 / 10000  - Loss =  0.0031934767  - ACC = 1.0\n",
            "Step 2325 / 10000  - Loss =  0.0031308657  - ACC = 1.0\n",
            "Step 2350 / 10000  - Loss =  0.0030704848  - ACC = 1.0\n",
            "Step 2375 / 10000  - Loss =  0.0030122504  - ACC = 1.0\n",
            "Step 2400 / 10000  - Loss =  0.002956173  - ACC = 1.0\n",
            "Step 2425 / 10000  - Loss =  0.0029021408  - ACC = 1.0\n",
            "Step 2450 / 10000  - Loss =  0.002850007  - ACC = 1.0\n",
            "Step 2475 / 10000  - Loss =  0.002799622  - ACC = 1.0\n",
            "Step 2500 / 10000  - Loss =  0.0027509537  - ACC = 1.0\n",
            "Step 2525 / 10000  - Loss =  0.0027039424  - ACC = 1.0\n",
            "Step 2550 / 10000  - Loss =  0.0026583185  - ACC = 1.0\n",
            "Step 2575 / 10000  - Loss =  0.0026139233  - ACC = 1.0\n",
            "Step 2600 / 10000  - Loss =  0.002570493  - ACC = 1.0\n",
            "Step 2625 / 10000  - Loss =  0.0025277517  - ACC = 1.0\n",
            "Step 2650 / 10000  - Loss =  0.0024863284  - ACC = 1.0\n",
            "Step 2675 / 10000  - Loss =  0.0024471434  - ACC = 1.0\n",
            "Step 2700 / 10000  - Loss =  0.0024094563  - ACC = 1.0\n",
            "Step 2725 / 10000  - Loss =  0.002372891  - ACC = 1.0\n",
            "Step 2750 / 10000  - Loss =  0.0023374243  - ACC = 1.0\n",
            "Step 2775 / 10000  - Loss =  0.0023029754  - ACC = 1.0\n",
            "Step 2800 / 10000  - Loss =  0.002269484  - ACC = 1.0\n",
            "Step 2825 / 10000  - Loss =  0.002236951  - ACC = 1.0\n",
            "Step 2850 / 10000  - Loss =  0.0022053109  - ACC = 1.0\n",
            "Step 2875 / 10000  - Loss =  0.0021745104  - ACC = 1.0\n",
            "Step 2900 / 10000  - Loss =  0.0021445192  - ACC = 1.0\n",
            "Step 2925 / 10000  - Loss =  0.0021152766  - ACC = 1.0\n",
            "Step 2950 / 10000  - Loss =  0.0020868299  - ACC = 1.0\n",
            "Step 2975 / 10000  - Loss =  0.0020591095  - ACC = 1.0\n",
            "Step 3000 / 10000  - Loss =  0.0020320811  - ACC = 1.0\n",
            "Step 3025 / 10000  - Loss =  0.0020057275  - ACC = 1.0\n",
            "Step 3050 / 10000  - Loss =  0.0019800104  - ACC = 1.0\n",
            "Step 3075 / 10000  - Loss =  0.001954898  - ACC = 1.0\n",
            "Step 3100 / 10000  - Loss =  0.0019303642  - ACC = 1.0\n",
            "Step 3125 / 10000  - Loss =  0.001906406  - ACC = 1.0\n",
            "Step 3150 / 10000  - Loss =  0.001883003  - ACC = 1.0\n",
            "Step 3175 / 10000  - Loss =  0.0018601199  - ACC = 1.0\n",
            "Step 3200 / 10000  - Loss =  0.0018377545  - ACC = 1.0\n",
            "Step 3225 / 10000  - Loss =  0.0018158926  - ACC = 1.0\n",
            "Step 3250 / 10000  - Loss =  0.0017945053  - ACC = 1.0\n",
            "Step 3275 / 10000  - Loss =  0.0017735695  - ACC = 1.0\n",
            "Step 3300 / 10000  - Loss =  0.001753104  - ACC = 1.0\n",
            "Step 3325 / 10000  - Loss =  0.0017330843  - ACC = 1.0\n",
            "Step 3350 / 10000  - Loss =  0.0017135001  - ACC = 1.0\n",
            "Step 3375 / 10000  - Loss =  0.0016943368  - ACC = 1.0\n",
            "Step 3400 / 10000  - Loss =  0.00167558  - ACC = 1.0\n",
            "Step 3425 / 10000  - Loss =  0.0016572119  - ACC = 1.0\n",
            "Step 3450 / 10000  - Loss =  0.0016392244  - ACC = 1.0\n",
            "Step 3475 / 10000  - Loss =  0.0016216034  - ACC = 1.0\n",
            "Step 3500 / 10000  - Loss =  0.0016043367  - ACC = 1.0\n",
            "Step 3525 / 10000  - Loss =  0.0015874149  - ACC = 1.0\n",
            "Step 3550 / 10000  - Loss =  0.001570831  - ACC = 1.0\n",
            "Step 3575 / 10000  - Loss =  0.0015545698  - ACC = 1.0\n",
            "Step 3600 / 10000  - Loss =  0.0015386271  - ACC = 1.0\n",
            "Step 3625 / 10000  - Loss =  0.0015229966  - ACC = 1.0\n",
            "Step 3650 / 10000  - Loss =  0.0015076712  - ACC = 1.0\n",
            "Step 3675 / 10000  - Loss =  0.0014926381  - ACC = 1.0\n",
            "Step 3700 / 10000  - Loss =  0.0014778895  - ACC = 1.0\n",
            "Step 3725 / 10000  - Loss =  0.0014634245  - ACC = 1.0\n",
            "Step 3750 / 10000  - Loss =  0.0014492269  - ACC = 1.0\n",
            "Step 3775 / 10000  - Loss =  0.0014352928  - ACC = 1.0\n",
            "Step 3800 / 10000  - Loss =  0.0014216088  - ACC = 1.0\n",
            "Step 3825 / 10000  - Loss =  0.001408168  - ACC = 1.0\n",
            "Step 3850 / 10000  - Loss =  0.0013949684  - ACC = 1.0\n",
            "Step 3875 / 10000  - Loss =  0.0013819988  - ACC = 1.0\n",
            "Step 3900 / 10000  - Loss =  0.0013692573  - ACC = 1.0\n",
            "Step 3925 / 10000  - Loss =  0.0013567397  - ACC = 1.0\n",
            "Step 3950 / 10000  - Loss =  0.0013444361  - ACC = 1.0\n",
            "Step 3975 / 10000  - Loss =  0.0013323422  - ACC = 1.0\n",
            "Step 4000 / 10000  - Loss =  0.0013204505  - ACC = 1.0\n",
            "Step 4025 / 10000  - Loss =  0.0013087594  - ACC = 1.0\n",
            "Step 4050 / 10000  - Loss =  0.001297266  - ACC = 1.0\n",
            "Step 4075 / 10000  - Loss =  0.0012859633  - ACC = 1.0\n",
            "Step 4100 / 10000  - Loss =  0.0012748153  - ACC = 1.0\n",
            "Step 4125 / 10000  - Loss =  0.0012638182  - ACC = 1.0\n",
            "Step 4150 / 10000  - Loss =  0.001253  - ACC = 1.0\n",
            "Step 4175 / 10000  - Loss =  0.0012423564  - ACC = 1.0\n",
            "Step 4200 / 10000  - Loss =  0.0012318819  - ACC = 1.0\n",
            "Step 4225 / 10000  - Loss =  0.0012215758  - ACC = 1.0\n",
            "Step 4250 / 10000  - Loss =  0.0012114225  - ACC = 1.0\n",
            "Step 4275 / 10000  - Loss =  0.0012014279  - ACC = 1.0\n",
            "Step 4300 / 10000  - Loss =  0.0011915904  - ACC = 1.0\n",
            "Step 4325 / 10000  - Loss =  0.0011819049  - ACC = 1.0\n",
            "Step 4350 / 10000  - Loss =  0.0011723671  - ACC = 1.0\n",
            "Step 4375 / 10000  - Loss =  0.0011629733  - ACC = 1.0\n",
            "Step 4400 / 10000  - Loss =  0.0011537204  - ACC = 1.0\n",
            "Step 4425 / 10000  - Loss =  0.0011446071  - ACC = 1.0\n",
            "Step 4450 / 10000  - Loss =  0.0011356273  - ACC = 1.0\n",
            "Step 4475 / 10000  - Loss =  0.001126781  - ACC = 1.0\n",
            "Step 4500 / 10000  - Loss =  0.0011180751  - ACC = 1.0\n",
            "Step 4525 / 10000  - Loss =  0.0011094935  - ACC = 1.0\n",
            "Step 4550 / 10000  - Loss =  0.0011010388  - ACC = 1.0\n",
            "Step 4575 / 10000  - Loss =  0.0010927061  - ACC = 1.0\n",
            "Step 4600 / 10000  - Loss =  0.0010844968  - ACC = 1.0\n",
            "Step 4625 / 10000  - Loss =  0.0010764047  - ACC = 1.0\n",
            "Step 4650 / 10000  - Loss =  0.0010684235  - ACC = 1.0\n",
            "Step 4675 / 10000  - Loss =  0.0010605541  - ACC = 1.0\n",
            "Step 4700 / 10000  - Loss =  0.0010527939  - ACC = 1.0\n",
            "Step 4725 / 10000  - Loss =  0.001045141  - ACC = 1.0\n",
            "Step 4750 / 10000  - Loss =  0.0010375951  - ACC = 1.0\n",
            "Step 4775 / 10000  - Loss =  0.0010301498  - ACC = 1.0\n",
            "Step 4800 / 10000  - Loss =  0.0010228045  - ACC = 1.0\n",
            "Step 4825 / 10000  - Loss =  0.0010155574  - ACC = 1.0\n",
            "Step 4850 / 10000  - Loss =  0.0010084074  - ACC = 1.0\n",
            "Step 4875 / 10000  - Loss =  0.0010013507  - ACC = 1.0\n",
            "Step 4900 / 10000  - Loss =  0.0009943893  - ACC = 1.0\n",
            "Step 4925 / 10000  - Loss =  0.0009875165  - ACC = 1.0\n",
            "Step 4950 / 10000  - Loss =  0.0009807338  - ACC = 1.0\n",
            "Step 4975 / 10000  - Loss =  0.00097403774  - ACC = 1.0\n",
            "Step 5000 / 10000  - Loss =  0.00096742826  - ACC = 1.0\n",
            "Step 5025 / 10000  - Loss =  0.0009609027  - ACC = 1.0\n",
            "Step 5050 / 10000  - Loss =  0.00095446  - ACC = 1.0\n",
            "Step 5075 / 10000  - Loss =  0.00094809564  - ACC = 1.0\n",
            "Step 5100 / 10000  - Loss =  0.00094181043  - ACC = 1.0\n",
            "Step 5125 / 10000  - Loss =  0.0009356029  - ACC = 1.0\n",
            "Step 5150 / 10000  - Loss =  0.0009294722  - ACC = 1.0\n",
            "Step 5175 / 10000  - Loss =  0.00092342385  - ACC = 1.0\n",
            "Step 5200 / 10000  - Loss =  0.00091744773  - ACC = 1.0\n",
            "Step 5225 / 10000  - Loss =  0.0009115474  - ACC = 1.0\n",
            "Step 5250 / 10000  - Loss =  0.0009057168  - ACC = 1.0\n",
            "Step 5275 / 10000  - Loss =  0.0008999566  - ACC = 1.0\n",
            "Step 5300 / 10000  - Loss =  0.000894265  - ACC = 1.0\n",
            "Step 5325 / 10000  - Loss =  0.0008886426  - ACC = 1.0\n",
            "Step 5350 / 10000  - Loss =  0.00088308565  - ACC = 1.0\n",
            "Step 5375 / 10000  - Loss =  0.0008775941  - ACC = 1.0\n",
            "Step 5400 / 10000  - Loss =  0.000872166  - ACC = 1.0\n",
            "Step 5425 / 10000  - Loss =  0.0008668015  - ACC = 1.0\n",
            "Step 5450 / 10000  - Loss =  0.00086149777  - ACC = 1.0\n",
            "Step 5475 / 10000  - Loss =  0.0008562566  - ACC = 1.0\n",
            "Step 5500 / 10000  - Loss =  0.0008510746  - ACC = 1.0\n",
            "Step 5525 / 10000  - Loss =  0.0008459516  - ACC = 1.0\n",
            "Step 5550 / 10000  - Loss =  0.00084088417  - ACC = 1.0\n",
            "Step 5575 / 10000  - Loss =  0.0008358707  - ACC = 1.0\n",
            "Step 5600 / 10000  - Loss =  0.00083091564  - ACC = 1.0\n",
            "Step 5625 / 10000  - Loss =  0.00082601514  - ACC = 1.0\n",
            "Step 5650 / 10000  - Loss =  0.00082117046  - ACC = 1.0\n",
            "Step 5675 / 10000  - Loss =  0.00081637764  - ACC = 1.0\n",
            "Step 5700 / 10000  - Loss =  0.0008116376  - ACC = 1.0\n",
            "Step 5725 / 10000  - Loss =  0.0008068963  - ACC = 1.0\n",
            "Step 5750 / 10000  - Loss =  0.0008021801  - ACC = 1.0\n",
            "Step 5775 / 10000  - Loss =  0.00079751667  - ACC = 1.0\n",
            "Step 5800 / 10000  - Loss =  0.00079290627  - ACC = 1.0\n",
            "Step 5825 / 10000  - Loss =  0.00078834733  - ACC = 1.0\n",
            "Step 5850 / 10000  - Loss =  0.00078383705  - ACC = 1.0\n",
            "Step 5875 / 10000  - Loss =  0.00077937625  - ACC = 1.0\n",
            "Step 5900 / 10000  - Loss =  0.00077496254  - ACC = 1.0\n",
            "Step 5925 / 10000  - Loss =  0.0007705981  - ACC = 1.0\n",
            "Step 5950 / 10000  - Loss =  0.00076627993  - ACC = 1.0\n",
            "Step 5975 / 10000  - Loss =  0.00076201017  - ACC = 1.0\n",
            "Step 6000 / 10000  - Loss =  0.00075778546  - ACC = 1.0\n",
            "Step 6025 / 10000  - Loss =  0.00075360475  - ACC = 1.0\n",
            "Step 6050 / 10000  - Loss =  0.0007494667  - ACC = 1.0\n",
            "Step 6075 / 10000  - Loss =  0.00074537384  - ACC = 1.0\n",
            "Step 6100 / 10000  - Loss =  0.0007413201  - ACC = 1.0\n",
            "Step 6125 / 10000  - Loss =  0.00073730724  - ACC = 1.0\n",
            "Step 6150 / 10000  - Loss =  0.00073333783  - ACC = 1.0\n",
            "Step 6175 / 10000  - Loss =  0.0007294085  - ACC = 1.0\n",
            "Step 6200 / 10000  - Loss =  0.0007255188  - ACC = 1.0\n",
            "Step 6225 / 10000  - Loss =  0.00072166737  - ACC = 1.0\n",
            "Step 6250 / 10000  - Loss =  0.00071785535  - ACC = 1.0\n",
            "Step 6275 / 10000  - Loss =  0.000714082  - ACC = 1.0\n",
            "Step 6300 / 10000  - Loss =  0.00071034604  - ACC = 1.0\n",
            "Step 6325 / 10000  - Loss =  0.00070664665  - ACC = 1.0\n",
            "Step 6350 / 10000  - Loss =  0.00070298364  - ACC = 1.0\n",
            "Step 6375 / 10000  - Loss =  0.00069935614  - ACC = 1.0\n",
            "Step 6400 / 10000  - Loss =  0.00069576385  - ACC = 1.0\n",
            "Step 6425 / 10000  - Loss =  0.0006922067  - ACC = 1.0\n",
            "Step 6450 / 10000  - Loss =  0.000688683  - ACC = 1.0\n",
            "Step 6475 / 10000  - Loss =  0.0006851929  - ACC = 1.0\n",
            "Step 6500 / 10000  - Loss =  0.00068173755  - ACC = 1.0\n",
            "Step 6525 / 10000  - Loss =  0.00067831593  - ACC = 1.0\n",
            "Step 6550 / 10000  - Loss =  0.000674926  - ACC = 1.0\n",
            "Step 6575 / 10000  - Loss =  0.00067156745  - ACC = 1.0\n",
            "Step 6600 / 10000  - Loss =  0.0006682424  - ACC = 1.0\n",
            "Step 6625 / 10000  - Loss =  0.0006649462  - ACC = 1.0\n",
            "Step 6650 / 10000  - Loss =  0.00066168  - ACC = 1.0\n",
            "Step 6675 / 10000  - Loss =  0.0006584459  - ACC = 1.0\n",
            "Step 6700 / 10000  - Loss =  0.00065524055  - ACC = 1.0\n",
            "Step 6725 / 10000  - Loss =  0.0006520654  - ACC = 1.0\n",
            "Step 6750 / 10000  - Loss =  0.00064891984  - ACC = 1.0\n",
            "Step 6775 / 10000  - Loss =  0.0006458029  - ACC = 1.0\n",
            "Step 6800 / 10000  - Loss =  0.00064271333  - ACC = 1.0\n",
            "Step 6825 / 10000  - Loss =  0.00063965295  - ACC = 1.0\n",
            "Step 6850 / 10000  - Loss =  0.00063662  - ACC = 1.0\n",
            "Step 6875 / 10000  - Loss =  0.0006336121  - ACC = 1.0\n",
            "Step 6900 / 10000  - Loss =  0.00063063175  - ACC = 1.0\n",
            "Step 6925 / 10000  - Loss =  0.00062767894  - ACC = 1.0\n",
            "Step 6950 / 10000  - Loss =  0.0006247519  - ACC = 1.0\n",
            "Step 6975 / 10000  - Loss =  0.0006218502  - ACC = 1.0\n",
            "Step 7000 / 10000  - Loss =  0.00061897526  - ACC = 1.0\n",
            "Step 7025 / 10000  - Loss =  0.0006161263  - ACC = 1.0\n",
            "Step 7050 / 10000  - Loss =  0.0006133011  - ACC = 1.0\n",
            "Step 7075 / 10000  - Loss =  0.0006105007  - ACC = 1.0\n",
            "Step 7100 / 10000  - Loss =  0.00060772256  - ACC = 1.0\n",
            "Step 7125 / 10000  - Loss =  0.00060496945  - ACC = 1.0\n",
            "Step 7150 / 10000  - Loss =  0.0006022251  - ACC = 1.0\n",
            "Step 7175 / 10000  - Loss =  0.0005994982  - ACC = 1.0\n",
            "Step 7200 / 10000  - Loss =  0.000596796  - ACC = 1.0\n",
            "Step 7225 / 10000  - Loss =  0.000594117  - ACC = 1.0\n",
            "Step 7250 / 10000  - Loss =  0.0005914568  - ACC = 1.0\n",
            "Step 7275 / 10000  - Loss =  0.0005888234  - ACC = 1.0\n",
            "Step 7300 / 10000  - Loss =  0.0005862158  - ACC = 1.0\n",
            "Step 7325 / 10000  - Loss =  0.00058363244  - ACC = 1.0\n",
            "Step 7350 / 10000  - Loss =  0.0005810672  - ACC = 1.0\n",
            "Step 7375 / 10000  - Loss =  0.0005785228  - ACC = 1.0\n",
            "Step 7400 / 10000  - Loss =  0.00057599973  - ACC = 1.0\n",
            "Step 7425 / 10000  - Loss =  0.0005734968  - ACC = 1.0\n",
            "Step 7450 / 10000  - Loss =  0.00057101547  - ACC = 1.0\n",
            "Step 7475 / 10000  - Loss =  0.0005685536  - ACC = 1.0\n",
            "Step 7500 / 10000  - Loss =  0.0005661125  - ACC = 1.0\n",
            "Step 7525 / 10000  - Loss =  0.00056369306  - ACC = 1.0\n",
            "Step 7550 / 10000  - Loss =  0.00056129316  - ACC = 1.0\n",
            "Step 7575 / 10000  - Loss =  0.0005589163  - ACC = 1.0\n",
            "Step 7600 / 10000  - Loss =  0.00055657234  - ACC = 1.0\n",
            "Step 7625 / 10000  - Loss =  0.0005542585  - ACC = 1.0\n",
            "Step 7650 / 10000  - Loss =  0.0005519633  - ACC = 1.0\n",
            "Step 7675 / 10000  - Loss =  0.0005496844  - ACC = 1.0\n",
            "Step 7700 / 10000  - Loss =  0.00054742576  - ACC = 1.0\n",
            "Step 7725 / 10000  - Loss =  0.0005451828  - ACC = 1.0\n",
            "Step 7750 / 10000  - Loss =  0.00054295827  - ACC = 1.0\n",
            "Step 7775 / 10000  - Loss =  0.0005407496  - ACC = 1.0\n",
            "Step 7800 / 10000  - Loss =  0.000538561  - ACC = 1.0\n",
            "Step 7825 / 10000  - Loss =  0.0005363869  - ACC = 1.0\n",
            "Step 7850 / 10000  - Loss =  0.00053423044  - ACC = 1.0\n",
            "Step 7875 / 10000  - Loss =  0.0005320892  - ACC = 1.0\n",
            "Step 7900 / 10000  - Loss =  0.00052996556  - ACC = 1.0\n",
            "Step 7925 / 10000  - Loss =  0.0005278562  - ACC = 1.0\n",
            "Step 7950 / 10000  - Loss =  0.0005257641  - ACC = 1.0\n",
            "Step 7975 / 10000  - Loss =  0.00052368676  - ACC = 1.0\n",
            "Step 8000 / 10000  - Loss =  0.0005216251  - ACC = 1.0\n",
            "Step 8025 / 10000  - Loss =  0.00051957875  - ACC = 1.0\n",
            "Step 8050 / 10000  - Loss =  0.000517547  - ACC = 1.0\n",
            "Step 8075 / 10000  - Loss =  0.0005155297  - ACC = 1.0\n",
            "Step 8100 / 10000  - Loss =  0.00051352795  - ACC = 1.0\n",
            "Step 8125 / 10000  - Loss =  0.00051153917  - ACC = 1.0\n",
            "Step 8150 / 10000  - Loss =  0.0005095667  - ACC = 1.0\n",
            "Step 8175 / 10000  - Loss =  0.00050760835  - ACC = 1.0\n",
            "Step 8200 / 10000  - Loss =  0.00050566375  - ACC = 1.0\n",
            "Step 8225 / 10000  - Loss =  0.0005037337  - ACC = 1.0\n",
            "Step 8250 / 10000  - Loss =  0.00050181913  - ACC = 1.0\n",
            "Step 8275 / 10000  - Loss =  0.00049991935  - ACC = 1.0\n",
            "Step 8300 / 10000  - Loss =  0.0004980349  - ACC = 1.0\n",
            "Step 8325 / 10000  - Loss =  0.0004961651  - ACC = 1.0\n",
            "Step 8350 / 10000  - Loss =  0.00049430603  - ACC = 1.0\n",
            "Step 8375 / 10000  - Loss =  0.00049246143  - ACC = 1.0\n",
            "Step 8400 / 10000  - Loss =  0.0004906287  - ACC = 1.0\n",
            "Step 8425 / 10000  - Loss =  0.0004888074  - ACC = 1.0\n",
            "Step 8450 / 10000  - Loss =  0.00048699984  - ACC = 1.0\n",
            "Step 8475 / 10000  - Loss =  0.00048520486  - ACC = 1.0\n",
            "Step 8500 / 10000  - Loss =  0.00048342452  - ACC = 1.0\n",
            "Step 8525 / 10000  - Loss =  0.00048165375  - ACC = 1.0\n",
            "Step 8550 / 10000  - Loss =  0.00047989612  - ACC = 1.0\n",
            "Step 8575 / 10000  - Loss =  0.00047815085  - ACC = 1.0\n",
            "Step 8600 / 10000  - Loss =  0.0004764165  - ACC = 1.0\n",
            "Step 8625 / 10000  - Loss =  0.00047469453  - ACC = 1.0\n",
            "Step 8650 / 10000  - Loss =  0.00047298346  - ACC = 1.0\n",
            "Step 8675 / 10000  - Loss =  0.0004712862  - ACC = 1.0\n",
            "Step 8700 / 10000  - Loss =  0.00046959912  - ACC = 1.0\n",
            "Step 8725 / 10000  - Loss =  0.00046792295  - ACC = 1.0\n",
            "Step 8750 / 10000  - Loss =  0.00046625937  - ACC = 1.0\n",
            "Step 8775 / 10000  - Loss =  0.00046460604  - ACC = 1.0\n",
            "Step 8800 / 10000  - Loss =  0.00046296456  - ACC = 1.0\n",
            "Step 8825 / 10000  - Loss =  0.00046133256  - ACC = 1.0\n",
            "Step 8850 / 10000  - Loss =  0.00045971113  - ACC = 1.0\n",
            "Step 8875 / 10000  - Loss =  0.00045809982  - ACC = 1.0\n",
            "Step 8900 / 10000  - Loss =  0.00045649835  - ACC = 1.0\n",
            "Step 8925 / 10000  - Loss =  0.0004549072  - ACC = 1.0\n",
            "Step 8950 / 10000  - Loss =  0.000453327  - ACC = 1.0\n",
            "Step 8975 / 10000  - Loss =  0.0004517571  - ACC = 1.0\n",
            "Step 9000 / 10000  - Loss =  0.00045019807  - ACC = 1.0\n",
            "Step 9025 / 10000  - Loss =  0.00044864754  - ACC = 1.0\n",
            "Step 9050 / 10000  - Loss =  0.00044710768  - ACC = 1.0\n",
            "Step 9075 / 10000  - Loss =  0.0004455776  - ACC = 1.0\n",
            "Step 9100 / 10000  - Loss =  0.0004440586  - ACC = 1.0\n",
            "Step 9125 / 10000  - Loss =  0.00044254703  - ACC = 1.0\n",
            "Step 9150 / 10000  - Loss =  0.00044104338  - ACC = 1.0\n",
            "Step 9175 / 10000  - Loss =  0.00043954796  - ACC = 1.0\n",
            "Step 9200 / 10000  - Loss =  0.00043806562  - ACC = 1.0\n",
            "Step 9225 / 10000  - Loss =  0.00043659142  - ACC = 1.0\n",
            "Step 9250 / 10000  - Loss =  0.00043512665  - ACC = 1.0\n",
            "Step 9275 / 10000  - Loss =  0.00043367277  - ACC = 1.0\n",
            "Step 9300 / 10000  - Loss =  0.00043222698  - ACC = 1.0\n",
            "Step 9325 / 10000  - Loss =  0.000430789  - ACC = 1.0\n",
            "Step 9350 / 10000  - Loss =  0.0004293605  - ACC = 1.0\n",
            "Step 9375 / 10000  - Loss =  0.00042793996  - ACC = 1.0\n",
            "Step 9400 / 10000  - Loss =  0.0004265292  - ACC = 1.0\n",
            "Step 9425 / 10000  - Loss =  0.00042512757  - ACC = 1.0\n",
            "Step 9450 / 10000  - Loss =  0.00042373384  - ACC = 1.0\n",
            "Step 9475 / 10000  - Loss =  0.00042234987  - ACC = 1.0\n",
            "Step 9500 / 10000  - Loss =  0.00042097448  - ACC = 1.0\n",
            "Step 9525 / 10000  - Loss =  0.00041960616  - ACC = 1.0\n",
            "Step 9550 / 10000  - Loss =  0.00041824713  - ACC = 1.0\n",
            "Step 9575 / 10000  - Loss =  0.00041689636  - ACC = 1.0\n",
            "Step 9600 / 10000  - Loss =  0.00041555226  - ACC = 1.0\n",
            "Step 9625 / 10000  - Loss =  0.0004142184  - ACC = 1.0\n",
            "Step 9650 / 10000  - Loss =  0.0004128934  - ACC = 1.0\n",
            "Step 9675 / 10000  - Loss =  0.00041157615  - ACC = 1.0\n",
            "Step 9700 / 10000  - Loss =  0.00041026692  - ACC = 1.0\n",
            "Step 9725 / 10000  - Loss =  0.0004089663  - ACC = 1.0\n",
            "Step 9750 / 10000  - Loss =  0.00040767217  - ACC = 1.0\n",
            "Step 9775 / 10000  - Loss =  0.00040638528  - ACC = 1.0\n",
            "Step 9800 / 10000  - Loss =  0.0004051077  - ACC = 1.0\n",
            "Step 9825 / 10000  - Loss =  0.00040383692  - ACC = 1.0\n",
            "Step 9850 / 10000  - Loss =  0.0004025727  - ACC = 1.0\n",
            "Step 9875 / 10000  - Loss =  0.00040131673  - ACC = 1.0\n",
            "Step 9900 / 10000  - Loss =  0.00040006696  - ACC = 1.0\n",
            "Step 9925 / 10000  - Loss =  0.00039882385  - ACC = 1.0\n",
            "Step 9950 / 10000  - Loss =  0.00039759002  - ACC = 1.0\n",
            "Step 9975 / 10000  - Loss =  0.00039636242  - ACC = 1.0\n",
            "---Generando animación ----\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' HTML(ani.to_html_5_video()) '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#keras"
      ],
      "metadata": {
        "id": "spNWL1OVce7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "lr = 0.01   # learning rate\n",
        "nn = [2, 16, 8, 1] # número de neuronas por capa.\n",
        "\n",
        "#creamos el objeto que contendrá a nuestra red neuronal, como\n",
        "# secuencia de capas.\n",
        "model = kr.Sequential()\n",
        "\n",
        "#añadimos la capa 1\n",
        "l1 = model.add(kr.layers.Dense(nn[1], activation='relu'))\n",
        "\n",
        "#añadimos la capa 2\n",
        "l2 = model.add(kr.layers.Dense(nn[2], activation='relu'))\n",
        "\n",
        "#añadimos la capa 3\n",
        "l3 = model.add(kr.layers.Dense(nn[3], activation='sigmoid'))\n",
        "\n",
        "#compilamos el modelo, definiendo la función de coste y le optimizador.\n",
        "model.compile(loss='mse', optimizer=kr.optimizers.SGD(lr=0.05), metrics=['acc'])\n",
        "# y se entrena el modelo. los callbacks\n",
        "model.fit(X, Y, epochs=100)"
      ],
      "metadata": {
        "id": "fOV2Px6FK-8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "0d7fd196-f647-4f7f-a648-cd83c60f8807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "tf.enable_eager_execution must be called at program startup.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-1800e55a9108>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   4854\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Enabling eager execution\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4855\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4856\u001b[0;31m     return enable_eager_execution_internal(\n\u001b[0m\u001b[1;32m   4857\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4858\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   4918\u001b[0m         _default_graph_stack._global_default_graph is not None)  # pylint: disable=protected-access\n\u001b[1;32m   4919\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4920\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   4921\u001b[0m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[1;32m   4922\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "lr = 0.01   # learning rate\n",
        "nn = [2, 16, 8, 1] # número de neuronas por capa.\n",
        "\n",
        "#creamos el objeto que contendrá a nuestra red neuronal, como\n",
        "# secuencia de capas.\n",
        "model = kr.Sequential()\n",
        "\n",
        "#añadimos la capa 1\n",
        "l1 = model.add(kr.layers.Dense(nn[1], activation='relu'))\n",
        "\n",
        "#añadimos la capa 2\n",
        "l2 = model.add(kr.layers.Dense(nn[2], activation='relu'))\n",
        "\n",
        "#añadimos la capa 3\n",
        "l3 = model.add(kr.layers.Dense(nn[3], activation='sigmoid'))\n",
        "\n",
        "#compilamos el modelo, definiendo la función de coste y le optimizador.\n",
        "model.compile(loss='mse', optimizer=kr.optimizers.SGD(learning_rate=0.05), metrics=['acc'])\n",
        "# y se entrena el modelo. los callbacks\n",
        "# Suponiendo que X e Y son tus datos de entrada y salida\n",
        "model.fit(X, Y, epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "e2DcdHRKSdpb",
        "outputId": "21c56972-baf3-4e37-891c-52710c5e71c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "numpy() is only available when eager execution is enabled.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ff4f0d765fe5>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#compilamos el modelo, definiendo la función de coste y le optimizador.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# y se entrena el modelo. los callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Suponiendo que X e Y son tus datos de entrada y salida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 )\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         is_any_keras_optimizer_v1 = any(\n\u001b[1;32m    323\u001b[0m             (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py\u001b[0m in \u001b[0;36m_set_optimizer\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         if self._dtype_policy.name == \"mixed_float16\" and not isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;31m# If TF2 is disabled, we convert to the legacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;31m# optimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_legacy_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# Wrap legacy TF optimizer instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36mconvert_to_legacy_optimizer\u001b[0;34m(optimizer)\u001b[0m\n\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[0moptimizer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Remove fields that only exist in experimental optimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     keys_to_remove = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/sgd.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         config.update(\n\u001b[1;32m    194\u001b[0m             {\n\u001b[0;32m--> 195\u001b[0;31m                 \"learning_rate\": self._serialize_hyperparameter(\n\u001b[0m\u001b[1;32m    196\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\u001b[0m in \u001b[0;36m_serialize_hyperparameter\u001b[0;34m(self, hyperparameter)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhyperparameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhyperparameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    691\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: numpy() is only available when eager execution is enabled."
          ]
        }
      ]
    }
  ]
}